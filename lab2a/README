NAME: Naim Ayat
EMAIL: naimayat@ucla.edu
ID: 000000000
This is my submission for Lab 2A (Races and Synchronization).
It is a tarball containing the following files:

	lab2_add.c:  implements and tests a shared variable add function, implements
	the specified command line options, and produces the specified output stats.
	lab2_list.c: implements the specified command line options and produces the
	specified output statistics.

	SortedList.h: describes the interfaces for linked list operations.
	SortedList.c: implements insert, delete, lookup, and length methods for a
	sorted doubly linked list.

	lab2_add.csv: contains results for all of the Part-1 tests.
	lab2_list.csv: contains results for all of the Part-2 tests.

	tests.sh: runs tests lab2_add and lab2_list, then records results in .csv.

	lab2_add-1.png: threads and iterations required to generate a failure.
	lab2_add-2.png: average time per operation with and without yields.
	lab2_add-3.png: average time per (single threaded) operation vs. the number of
	iterations.
	lab2_add-4.png: threads and iterations that can run successfully with yields
	under each of the synchronization options.
	lab2_add-5.png: average time per (protected) operation vs. the number of
	threads.
	lab2_list-1.png: average time per (single threaded) unprotected operation vs.
	number of iterations (illustrating the correction of the per-operation cost
	for the list length).
	lab2_list-2.png: threads and iterations required to generate a failure (with
	and without yields).
	lab2_list-3.png: iterations that can run (protected) without failure.
	lab2_list-4.png: (length-adjusted) cost per operation vs the number of threads
	for the various synchronization options.

	Makefile:
		default: compiles all programs (with the -Wall and -Wextra options).
		tests: executes tests.sh
		graphs: employs gnuplot and data reduction scripts to generate graphs.
		dist: creates the deliverable tarball
		clean: deletes all programs and output created by Makefile.

	README
	______________________________________________________________________________

QUESTION 2.1.1 - causing conflicts:
	Why does it take many iterations before errors are seen?
		In this case, an error occurs when a thread wants to load a resource while
		another thread is modifying it. Simply put, the more iterations we have, the
		more operations we carry out; thus increasing the potential for threads	to
		conflict with one another in this manner.

	Why does a significantly smaller number of iterations so seldom fail?
		With fewer iterations, there is less chance that the situation will arise in
		which a thread tries to load a resource while another thread modifies it.

QUESTION 2.1.2 - cost of yielding:
	Why are the --yield runs so much slower?
		Yield runs are much slower because yielding the execution of a thread
		triggers a context switch, which is costly.

	Where is the additional time going?
		The time goes to saving register states into memory for the context switch.

	Is it possible to get valid per-operation timings if we are using the --yield
	option?
		It is not.

	If so, explain how. If not, explain why not.
		Context switching and scheduling creates additional overhead, thus greatly
		increasing execution time. The timing of sched_yield() is unpredictable.

QUESTION 2.1.3 - measurement errors:
	Why does the average cost per operation drop with increasing iterations?
		Usually, the overhead from creating a thread is fixed. When there are more
		iterations, each thread must perform a proportionally greater number of
		instructions, thus reducing the costs associated with thread creation and
		context switching.

	If the cost per iteration is a function of the number of iterations, how do we
	know how many iterations to run (or what the "correct" cost is)?
		We can plot the data of execution time vs. number of iterations with a large
		sample size and extract a model for the "correct" cost from it.

QUESTION 2.1.4 - costs of serialization:
	Why do all of the options perform similarly for low numbers of threads?
		By similar principle to question (2.1.1), a low number of threads is
		associated with a low probability of synchronization errors. Thus, there is
		less overhead from spin locks.

	Why do the three protected operations slow down as the number of threads
	rises?
		Opposite of the last question, a high number of threads is associated with a
		high probability of synchronization errors. Thus, there is a significant
		chance that threads will have to wait for locks, slowing execution time.

QUESTION 2.2.1 - scalability of Mutex
	Compare the variation in time per mutex-protected operation vs the number of
	threads in Part-1 (adds) and Part-2 (sorted lists).
		In Part-1, we observe that the time per mutex-protected operation increases
		with thread counts up to 4, then decreases as more are added. In Part-2, the
		time per mutex-protected operation increases with the number of threads
		without boundary.

	Comment on the general shapes of the curves, and explain why they have this
	shape. Comment on the relative rates of increase and differences in the shapes
	of the curves, and offer an explanation for these differences.
		The curve of Part-1 looks like an absolute value function inverted on the
		y-axis. Part-2 follows more of a parabola shape in the positive y-direction.
		We also note that, over time, Part-2 increases at a much quicker rate than
		Part-1. This is because Part-2 takes more time with mutex-protection. Thus,
		threads have to wait longer (relative to Part-1) as the thread count
		increases.

QUESTION 2.2.2 - scalability of spin locks
	Compare the variation in time per protected operation vs the number of threads
	for list operations protected by Mutex vs Spin locks. Comment on the general
	shapes of the curves, and explain why they have this shape. Comment on the
	relative rates of increase and differences in the shapes of the curves, and
	offer an explanation for these differences.
		In both cases (mutexes and spin locks) the execution time per protected
		operation increases with the addition of threads. However, we note that spin
		locks increase time at a quicker rate. This is because spin locks take
		longer; they must spin (at a cost) while waiting for locks to be lifted.
		Mutexes, on the other hand, allow the blocked thread to yield to another
		thread which can actually run.
